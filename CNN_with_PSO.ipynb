{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nbformat\n",
      "  Downloading nbformat-5.7.3-py3-none-any.whl (78 kB)\n",
      "     ---------------------------------------- 78.1/78.1 kB 1.1 MB/s eta 0:00:00\n",
      "Collecting jsonschema>=2.6\n",
      "  Downloading jsonschema-4.17.3-py3-none-any.whl (90 kB)\n",
      "     ---------------------------------------- 90.4/90.4 kB 2.6 MB/s eta 0:00:00\n",
      "Collecting fastjsonschema\n",
      "  Downloading fastjsonschema-2.16.3-py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: jupyter-core in c:\\users\\mariella\\miniconda3\\lib\\site-packages (from nbformat) (5.2.0)\n",
      "Requirement already satisfied: traitlets>=5.1 in c:\\users\\mariella\\miniconda3\\lib\\site-packages (from nbformat) (5.9.0)\n",
      "Collecting pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0\n",
      "  Downloading pyrsistent-0.19.3-cp38-cp38-win_amd64.whl (62 kB)\n",
      "     ---------------------------------------- 62.7/62.7 kB 3.3 MB/s eta 0:00:00\n",
      "Collecting importlib-resources>=1.4.0\n",
      "  Downloading importlib_resources-5.12.0-py3-none-any.whl (36 kB)\n",
      "Collecting pkgutil-resolve-name>=1.3.10\n",
      "  Downloading pkgutil_resolve_name-1.3.10-py3-none-any.whl (4.7 kB)\n",
      "Collecting attrs>=17.4.0\n",
      "  Downloading attrs-22.2.0-py3-none-any.whl (60 kB)\n",
      "     ---------------------------------------- 60.0/60.0 kB 3.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: platformdirs>=2.5 in c:\\users\\mariella\\miniconda3\\lib\\site-packages (from jupyter-core->nbformat) (3.0.0)\n",
      "Requirement already satisfied: pywin32>=1.0 in c:\\users\\mariella\\miniconda3\\lib\\site-packages (from jupyter-core->nbformat) (227)\n",
      "Requirement already satisfied: zipp>=3.1.0 in c:\\users\\mariella\\miniconda3\\lib\\site-packages (from importlib-resources>=1.4.0->jsonschema>=2.6->nbformat) (3.15.0)\n",
      "Installing collected packages: fastjsonschema, pyrsistent, pkgutil-resolve-name, importlib-resources, attrs, jsonschema, nbformat\n",
      "Successfully installed attrs-22.2.0 fastjsonschema-2.16.3 importlib-resources-5.12.0 jsonschema-4.17.3 nbformat-5.7.3 pkgutil-resolve-name-1.3.10 pyrsistent-0.19.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install nbformat\n",
    "\n",
    "%run PSO.ipynb #da qui possiamousare la funzione PSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = keras.datasets.cifar10.load_data()\n",
    "X_valid = X_train[4000:]\n",
    "y_valid = y_train[4000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(image,label):\n",
    "    image=tf.image.per_image_standardization(image)\n",
    "    image=tf.image.resize(image,(64,64))\n",
    "    \n",
    "    return image,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=keras.models.Sequential([\n",
    "    keras.layers.Conv2D(filters=128, kernel_size=(11,11), strides=(4,4), activation='relu', input_shape=(64,64,3)),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.MaxPool2D(pool_size=(2,2)),\n",
    "    keras.layers.Conv2D(filters=256, kernel_size=(5,5), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.MaxPool2D(pool_size=(3,3)),\n",
    "    keras.layers.Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Conv2D(filters=256, kernel_size=(1,1), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Conv2D(filters=256, kernel_size=(1,1), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.MaxPool2D(pool_size=(2,2)),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(1024,activation='relu'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(1024,activation='relu'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(10,activation='softmax')  \n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best position found:  [-0.0200253   0.01446194 -0.0031102 ] with an evaluation of:  0.0006198339423027385\n"
     ]
    }
   ],
   "source": [
    "# mi serve una funzione che prenda in input solo i parametri della pso e restituisca l'accuracy\n",
    "\n",
    "def CNN(batch_size, optimizer, learning_rate, X_train = X_train, y_train = y_train, x_valid = X_valid, y_valid = y_valid, model =   model):\n",
    "\n",
    "    X_train_size=tf.data.experimental.cardinality(X_train).numpy()\n",
    "    X_valid_size=tf.data.experimental.cardinality(X_valid).numpy()\n",
    "\n",
    "    train_ds = (X_train.map(process_image).shuffle(buffer_size = X_train_size).batch(batch_size=batch_size, drop_reminder = True))\n",
    "    valid_ds = (X_valid.map(process_image).shuffle(buffer_size = X_valid_size).batch(batch_size=batch_size, drop_reminder = True))\n",
    "\n",
    "    if optimizer < 1:\n",
    "        #use SGD\n",
    "        opt = tf.keras.optimizers.experimental.SGD(lr = learning_rate)\n",
    "        \n",
    "    if optimizer<=1 and optimizer < 2:\n",
    "        #use SGD with Momentum\n",
    "        opt = tf.keras.optimizers.experimental.SGD(momentum = 0.9, lr = learning_rate)\n",
    "\n",
    "    if optimizer >= 2 and optimizer < 3:\n",
    "        #use ADAM\n",
    "        opt = tf.keras.optimizers.Adam(lr = learning_rate)\n",
    "\n",
    "    if optimizer >= 3 and optimizer < 4:\n",
    "        #use RMSPROP\n",
    "        opt = tf.keras.optimizers.experimental.RMSprop(lr = learning_rate)\n",
    "\n",
    "    model.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer= opt,\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "    print(model.summary())\n",
    "\n",
    "    history=model.fit(\n",
    "    train_ds,\n",
    "    epochs=5,\n",
    "    validation_data=valid_ds,\n",
    "    validation_freq=1)\n",
    "\n",
    "    last_accuracy = history.history['val_accuracy'][-1]\n",
    "\n",
    "    return last_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    result = 0\n",
    "    for i in x:\n",
    "        result += i**2\n",
    "    return(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "main() got an unexpected keyword argument 'swarm_size'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m main(swarm_size \u001b[39m=\u001b[39;49m \u001b[39m30\u001b[39;49m,\n\u001b[0;32m      2\u001b[0m     dim \u001b[39m=\u001b[39;49m \u001b[39m3\u001b[39;49m,\n\u001b[0;32m      3\u001b[0m     evaluation_funct \u001b[39m=\u001b[39;49m f,\n\u001b[0;32m      4\u001b[0m     lower_bound\u001b[39m=\u001b[39;49m[\u001b[39m-\u001b[39;49m\u001b[39m10\u001b[39;49m,\u001b[39m-\u001b[39;49m\u001b[39m10\u001b[39;49m,\u001b[39m-\u001b[39;49m\u001b[39m10\u001b[39;49m],\n\u001b[0;32m      5\u001b[0m     upper_bound \u001b[39m=\u001b[39;49m [\u001b[39m10\u001b[39;49m,\u001b[39m10\u001b[39;49m,\u001b[39m10\u001b[39;49m],\n\u001b[0;32m      6\u001b[0m     v_max \u001b[39m=\u001b[39;49m [\u001b[39m3\u001b[39;49m,\u001b[39m3\u001b[39;49m,\u001b[39m3\u001b[39;49m],\n\u001b[0;32m      7\u001b[0m     problem \u001b[39m=\u001b[39;49m \u001b[39m'\u001b[39;49m\u001b[39mminimum\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[0;32m      8\u001b[0m     max_iteration \u001b[39m=\u001b[39;49m \u001b[39m200\u001b[39;49m)\n",
      "\u001b[1;31mTypeError\u001b[0m: main() got an unexpected keyword argument 'swarm_size'"
     ]
    }
   ],
   "source": [
    "main(swarm_size = 30,\n",
    "    dim = 3,\n",
    "    evaluation_funct = f,\n",
    "    lower_bound=[-10,-10,-10],\n",
    "    upper_bound = [10,10,10],\n",
    "    v_max = [3,3,3],\n",
    "    problem = 'minimum',\n",
    "    max_iteration = 200)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f15b3b7541721a7ac1e1c80e85784ec7d18e6ad136b144e690e927a80e691a8b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
