{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **IMAGE CLASSIFICATOR WITH PSO FOR HYPERPARAMETERS OPTIMIZATION**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition of the problem and main goal\n",
    "In this notebook we want to write a Convolutional Neural Network (CNN) with the aim of classify the images taken by the **CIFAR-10** dataset. Moreover we want to use **Particle Swarm Optimization** (PSO) in order to optimize some characteristics of the CNN concerning architecture and hyperparameters. The PSO has been implemented by us as a class called *INSERIRE NOME CLASSE"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CIFAR-10 dataset preprocessing\n",
    "Quoting directly the official webpage (https://www.cs.toronto.edu/~kriz/cifar.html):\n",
    "\"The CIFAR-10 dataset consists of 60000 32x32 colour images in 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images.\n",
    "\n",
    "The dataset is divided into five training batches and one test batch, each with 10000 images. The test batch contains exactly 1000 randomly-selected images from each class. The training batches contain the remaining images in random order, but some training batches may contain more images from one class than another. Between them, the training batches contain exactly 5000 images from each class.\n",
    "\n",
    "Here are the classes in the dataset, as well as 10 random images from each:\n",
    "\n",
    "<img src=\"Immagine 2023-02-08 183815.png\" alt=\"drawing\" width=\"50%\" height=\"40%\"/>\n",
    "\n",
    "The classes are completely mutually exclusive. There is no overlap between automobiles and trucks. \"Automobile\" includes sedans, SUVs, things of that sort. \"Truck\" includes only big trucks. Neither includes pickup trucks.\"\n",
    "\n",
    "By looking the webpage we know we can use the **unpickle** function for opening the 5 batches files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpickle(file):\n",
    "    import pickle\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As written on the webpage:\n",
    "\n",
    "\"Loaded in this way, each of the batch files contains a dictionary with the following elements:\n",
    "- **data**: a 10000x3072 numpy array of uint8s. Each row of the array stores a 32x32 colour image. The first 1024 entries contain the red channel values, the next 1024 the green, and the final 1024 the blue. The image is stored in row-major order, so that the first 32 entries of the array are the red channel values of the first row of the image.\n",
    "- **labels**: a list of 10000 numbers in the range 0-9. The number at index i indicates the label of the ith image in the array **data**.\n",
    "\n",
    "The dataset contains another file, called **batches.meta**. It too contains a Python dictionary object. It has the following entries:\n",
    "- **label_names** -- a 10-element list which gives meaningful names to the numeric labels in the labels array described above. For example, label_names[0] == \"airplane\", label_names[1] == \"automobile\", etc.\"\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://medium.com/@rhythm10/image-preprocessing-for-cifar-10-dataset-f2b5cdb221bb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " From the five training data files, we are first going to unpickle the data and then read it from the directory that the data has been stored at. We read the five data files by iterating over a loop to provide the name of the data file stored in the directory.\n",
    "\n",
    "Similarly, for testing data, we first unpickle the data and read it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_dir):\n",
    "    #load training data \n",
    "    for i in range(1, 6): \n",
    "        filename = data_dir+\"/data_batch_\"+str(i) \n",
    "        dictionary = unpickle(filename) \n",
    "        x_data = dictionary[b'data']  \n",
    "        y_data = np.array(dictionary[b\"labels\"])\n",
    "        if i==1:   \n",
    "            x_train = x_data  \n",
    "            y_train= y_data  \n",
    "        else:  \n",
    "            x_train = np.concatenate((x_train, x_data), axis = 0)   \n",
    "            y_train = np.concatenate((y_train, y_data), axis = 0)  \n",
    "\n",
    "    #load testing data \n",
    "    filename = data_dir+\"/test_batch\" \n",
    "    dictionary = unpickle(filename)\n",
    "    data = dictionary[b\"data\"]\n",
    "    x_test = data \n",
    "    y_test = np.array(dictionary[b\"labels\"]) \n",
    "    return x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_valid_split(x_train, y_train, split_index=45000):\n",
    "    '''split the input data based on the split index'''\n",
    "    x_train_new = x_train[:split_index] \n",
    "    y_train_new = y_train[:split_index] \n",
    "    x_valid = x_train[split_index:] \n",
    "    y_valid = y_train[split_index:]\n",
    "    return x_train_new, y_train_new, x_valid, y_valid"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After having defined the function we need, we can apply them to our files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train dataset has: 45000 element \n",
      " The validation dataset has: 5000 element \n",
      " The test dataset has: 10000 element \n",
      "\n",
      "The length of a single element is:  3072\n"
     ]
    }
   ],
   "source": [
    "data_dir = \"cifar-10-batches-py\"\n",
    "x_train, y_train, x_test, y_test = load_data(data_dir)\n",
    "\n",
    "#Let's split the train data into two sets: training and validation:\n",
    "x_train, y_train, x_valid, y_valid = train_valid_split(x_train, y_train, split_index=45000)\n",
    "\n",
    "print('The train dataset has:' , x_train.shape[0], 'element \\n', 'The validation dataset has:' , x_valid.shape[0], 'element \\n', 'The test dataset has:' , x_test.shape[0], 'element \\n',)\n",
    "\n",
    "print('The length of a single element is: ', x_train.shape[1])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first are going to parse our records in the data. Converting the image format from (depth * height * width) to first (depth ,height,width) and then to (width, height, depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_record(record, training=True):\n",
    "    '''Takes as input record which is an array of shape [3072,] and training which is a boolean variable used to determine if the process is in training mode and returns an array of shape [32,32,3]'''\n",
    "    depth_major = record.reshape((3, 32, 32))\n",
    "    image = np.transpose(depth_major, [1, 2, 0])\n",
    "    #image = preprocess_image(image, training)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45000, 3072)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Notice that before applying the parse_record function, the data shape is 45000 (number of image in the train) and 3072 that is 3*32*32 (depth*height*width)\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45000, 32, 32, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train=[]\n",
    "for img in x_train:\n",
    "    train.append(parse_record(img))\n",
    "\n",
    "valid=[]\n",
    "for img in x_valid:\n",
    "    valid.append(parse_record(img))\n",
    "\n",
    "test=[]\n",
    "for img in x_test:\n",
    "    test.append(parse_record(img))\n",
    "\n",
    "#Now we can see that the shape is no more 3072 but (32,32,3): (width, height, depth)\n",
    "np.array(train).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WE NEED TO NORMALIZE DATAAA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The label data is just a list of 10,000 numbers ranging from 0 to 9, which corresponds to each of the 10 classes in CIFAR-10.\n",
    "# airplane : 0, automobile : 1, bird : 2, cat : 3, deer : 4, dog : 5, frog : 6, horse : 7, ship : 8, truck : 9\n",
    "# We need to encode the target variable\n",
    "#FNIODHVNCKNAERIFOCJURAEPDLCV"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We decide to use the AlexNet as landmark.\n",
    "The architecture consists of 5 Convolutional layers, with the 1st, 2nd and 5th having Max-Pooling layers for proper feature extraction. The Max-Pooling layers are overlapped having strides of 2 with filter size 3×3. They are followed by 2 fully-connected layers (each with dropout) and a softmax layer at the end for predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow.python'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [11], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mkeras\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodels\u001b[39;00m \u001b[39mimport\u001b[39;00m Sequential\n\u001b[0;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlayers\u001b[39;00m \u001b[39mimport\u001b[39;00m Conv2D, Activation, MaxPooling2D, Flatten, Dense, Dropout\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\keras\\__init__.py:21\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[39m\"\"\"Implementation of the Keras API, the high-level API of TensorFlow.\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \n\u001b[0;32m     17\u001b[0m \u001b[39mDetailed documentation and user guides are available at\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[39m[keras.io](https://keras.io).\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m \u001b[39mimport\u001b[39;00m distribute\n\u001b[1;32m---> 21\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m \u001b[39mimport\u001b[39;00m models\n\u001b[0;32m     22\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39minput_layer\u001b[39;00m \u001b[39mimport\u001b[39;00m Input\n\u001b[0;32m     23\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msequential\u001b[39;00m \u001b[39mimport\u001b[39;00m Sequential\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\keras\\models\\__init__.py:18\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Copyright 2022 The TensorFlow Authors. All Rights Reserved.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[39m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[39m# limitations under the License.\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[39m# ==============================================================================\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[39m\"\"\"Keras models API.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfunctional\u001b[39;00m \u001b[39mimport\u001b[39;00m Functional\n\u001b[0;32m     19\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msequential\u001b[39;00m \u001b[39mimport\u001b[39;00m Sequential\n\u001b[0;32m     20\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtraining\u001b[39;00m \u001b[39mimport\u001b[39;00m Model\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\keras\\engine\\functional.py:24\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mitertools\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mwarnings\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcompat\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mv2\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtf\u001b[39;00m\n\u001b[0;32m     26\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m \u001b[39mimport\u001b[39;00m backend\n\u001b[0;32m     27\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdtensor\u001b[39;00m \u001b[39mimport\u001b[39;00m layout_map \u001b[39mas\u001b[39;00m layout_map_lib\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\tensorflow\\__init__.py:37\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39msys\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39m_sys\u001b[39;00m\n\u001b[0;32m     35\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtyping\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39m_typing\u001b[39;00m\n\u001b[1;32m---> 37\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtools\u001b[39;00m \u001b[39mimport\u001b[39;00m module_util \u001b[39mas\u001b[39;00m _module_util\n\u001b[0;32m     38\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutil\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlazy_loader\u001b[39;00m \u001b[39mimport\u001b[39;00m LazyLoader \u001b[39mas\u001b[39;00m _LazyLoader\n\u001b[0;32m     40\u001b[0m \u001b[39m# Make sure code inside the TensorFlow codebase can use tf2.enabled() at import.\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow.python'"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, Activation, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's build the AlexNet architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "  \n",
    "# 1st Convolutional Layer\n",
    "model.add(Conv2D(filters = 64, input_shape = (32, 32, 3), \n",
    "            kernel_size = (3, 3), strides = (2, 2), \n",
    "            padding = 'valid'))\n",
    "model.add(Activation('relu'))\n",
    "# Max-Pooling \n",
    "model.add(MaxPooling2D(pool_size = (2, 2),\n",
    "            strides = (2, 2), padding = 'valid'))\n",
    "# Batch Normalisation\n",
    "model.add(BatchNormalization())\n",
    "  \n",
    "\n",
    "# 2nd Convolutional Layer\n",
    "model.add(Conv2D(filters = 192, kernel_size = (3, 3), \n",
    "            strides = (1, 1), padding = 'valid'))\n",
    "model.add(Activation('relu'))\n",
    "# Max-Pooling\n",
    "model.add(MaxPooling2D(pool_size = (2, 2), strides = (2, 2), \n",
    "            padding = 'valid'))\n",
    "# Batch Normalisation\n",
    "model.add(BatchNormalization())\n",
    "  \n",
    "\n",
    "# 3rd Convolutional Layer\n",
    "model.add(Conv2D(filters = 384, kernel_size = (3, 3), \n",
    "            strides = (1, 1), padding = 'valid'))\n",
    "model.add(Activation('relu'))\n",
    "# Batch Normalisation\n",
    "model.add(BatchNormalization())\n",
    "  \n",
    "\n",
    "# 4th Convolutional Layer\n",
    "model.add(Conv2D(filters = 256, kernel_size = (3, 3), \n",
    "            strides = (1, 1), padding = 'valid'))\n",
    "model.add(Activation('relu'))\n",
    "# Batch Normalisation\n",
    "model.add(BatchNormalization())\n",
    "  \n",
    "\n",
    "# 5th Convolutional Layer\n",
    "model.add(Conv2D(filters = 256, kernel_size = (3, 3), \n",
    "            strides = (1, 1), padding = 'valid'))\n",
    "model.add(Activation('relu'))\n",
    "# Max-Pooling\n",
    "model.add(MaxPooling2D(pool_size = (2, 2), strides = (2, 2), \n",
    "            padding = 'valid'))\n",
    "# Batch Normalisation\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "\n",
    "# Flattening\n",
    "model.add(Flatten())\n",
    "  \n",
    "# 1st Dense Layer\n",
    "model.add(Dense(4096, input_shape = (224*224*3, )))\n",
    "model.add(Activation('relu'))\n",
    "# Add Dropout to prevent overfitting\n",
    "model.add(Dropout(0.4))\n",
    "# Batch Normalisation\n",
    "model.add(BatchNormalization())\n",
    "  \n",
    "# 2nd Dense Layer\n",
    "model.add(Dense(4096))\n",
    "model.add(Activation('relu'))\n",
    "# Add Dropout\n",
    "model.add(Dropout(0.4))\n",
    "# Batch Normalisation\n",
    "model.add(BatchNormalization())\n",
    "  \n",
    "# Output Softmax Layer\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "\n",
    "## Forse si può fare direttamente da qua\n",
    "# import torchvision.models as models\n",
    "# squeezenet = models.alexnet(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adam(),metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's train the model\n",
    "\n",
    "start_time = time.perf_counter()\n",
    "\n",
    "training = model.fit(x_train, y_train, batch_size=64,epochs=100,verbose=1,validation_data=(x_valid, y_valid))\n",
    "\n",
    "print(\"Execution time:\", time.perf_counter() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eval = model.evaluate(x_test, y_test, verbose=0)\n",
    "\n",
    "print('Test loss:', test_eval[0])\n",
    "print('Test accuracy:', test_eval[1])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We plot the accuracy and loss plots between training and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = training.history['acc']\n",
    "val_accuracy = training.history['val_acc']\n",
    "loss = training.history['loss']\n",
    "val_loss = training.history['val_loss']\n",
    "epochs = range(len(accuracy))\n",
    "plt.plot(epochs, accuracy, 'bo', label='Training accuracy')\n",
    "plt.plot(epochs, val_accuracy, 'b', label='Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "final_proj_astroinf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "15ba1ea02468f175d17ddd829e635cf9050c3adaa9ad27d8a1c3f3ecd6b990f3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
