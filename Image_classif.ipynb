{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **IMAGE CLASSIFICATOR WITH PSO FOR HYPERPARAMETERS OPTIMIZATION**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition of the problem and main goal\n",
    "In this notebook we want to write a Convolutional Neural Network (CNN) with the aim of classify the images taken by the **CIFAR-10** dataset. Moreover we want to use **Particle Swarm Optimization** (PSO) in order to optimize some characteristics of the CNN concerning architecture and hyperparameters. The PSO has been implemented by us as a class called *INSERIRE NOME CLASSE"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CIFAR-10 dataset preprocessing\n",
    "Quoting directly the official webpage (https://www.cs.toronto.edu/~kriz/cifar.html):\n",
    "\"The CIFAR-10 dataset consists of 60000 32x32 colour images in 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images.\n",
    "\n",
    "The dataset is divided into five training batches and one test batch, each with 10000 images. The test batch contains exactly 1000 randomly-selected images from each class. The training batches contain the remaining images in random order, but some training batches may contain more images from one class than another. Between them, the training batches contain exactly 5000 images from each class.\n",
    "\n",
    "Here are the classes in the dataset, as well as 10 random images from each:\n",
    "\n",
    "<img src=\"Immagine 2023-02-08 183815.png\" alt=\"drawing\" width=\"50%\" height=\"40%\"/>\n",
    "\n",
    "The classes are completely mutually exclusive. There is no overlap between automobiles and trucks. \"Automobile\" includes sedans, SUVs, things of that sort. \"Truck\" includes only big trucks. Neither includes pickup trucks.\"\n",
    "\n",
    "By looking the webpage we know we can use the **unpickle** function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpickle(file):\n",
    "    import pickle\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As written on the webpage:\n",
    "\n",
    "\"Loaded in this way, each of the batch files contains a dictionary with the following elements:\n",
    "- **data**: a 10000x3072 numpy array of uint8s. Each row of the array stores a 32x32 colour image. The first 1024 entries contain the red channel values, the next 1024 the green, and the final 1024 the blue. The image is stored in row-major order, so that the first 32 entries of the array are the red channel values of the first row of the image.\n",
    "- **labels**: a list of 10000 numbers in the range 0-9. The number at index i indicates the label of the ith image in the array **data**.\n",
    "\n",
    "The dataset contains another file, called **batches.meta**. It too contains a Python dictionary object. It has the following entries:\n",
    "- **label_names** -- a 10-element list which gives meaningful names to the numeric labels in the labels array described above. For example, label_names[0] == \"airplane\", label_names[1] == \"automobile\", etc.\"\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://medium.com/@rhythm10/image-preprocessing-for-cifar-10-dataset-f2b5cdb221bb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " From the five training data files, we are first going to unpickle the data and then read it from the directory that the data has been stored at. We read the five data files by iterating over a loop to provide the name of the data file stored in the directory.\n",
    "\n",
    "Similarly, for testing data, we first unpickle the data and read it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_dir):\n",
    "    #load training data \n",
    "    for i in range(1, 6): \n",
    "        filename = data_dir+\"/data_batch_\"+str(i) \n",
    "        dictionary = unpickle(filename) \n",
    "        x_data = dictionary[b'data']  \n",
    "        y_data = np.array(dictionary[b\"labels\"])\n",
    "        if i==1:   \n",
    "            x_train = x_data  \n",
    "            y_train= y_data  \n",
    "        else:  \n",
    "            x_train = np.concatenate((x_train, x_data), axis = 0)   \n",
    "            y_train = np.concatenate((y_train, y_data), axis = 0)  \n",
    "\n",
    "    #load testing data \n",
    "    filename = data_dir+\"/test_batch\" \n",
    "    dictionary = unpickle(filename)\n",
    "    data = dictionary[b\"data\"]\n",
    "    x_test = data \n",
    "    y_test = np.array(dictionary[b\"labels\"]) \n",
    "    return x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_valid_split(x_train, y_train, split_index=45000):\n",
    "    x_train_new = x_train[:split_index] \n",
    "    y_train_new = y_train[:split_index] \n",
    "    x_valid = x_train[split_index:] \n",
    "    y_valid = y_train[split_index:]\n",
    "    return x_train_new, y_train_new, x_valid, y_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train dataset has: 45000 element \n",
      " The validation dataset has: 5000 element \n",
      " The test dataset has: 10000 element \n",
      "\n",
      "The length of a single element is:  3072\n"
     ]
    }
   ],
   "source": [
    "data_dir = \"cifar-10-batches-py\"\n",
    "x_train, y_train, x_test, y_test = load_data(data_dir)\n",
    "\n",
    "x_train, y_train, x_valid, y_valid = train_valid_split(x_train, y_train, split_index=45000)\n",
    "\n",
    "print('The train dataset has:' , x_train.shape[0], 'element \\n', 'The validation dataset has:' , x_valid.shape[0], 'element \\n', 'The test dataset has:' , x_test.shape[0], 'element \\n',)\n",
    "\n",
    "print('The length of a single element is: ', x_train.shape[1])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first are going to parse our records in the data. Converting the image format from (depth * height * width) to first (depth ,height,width) and then to (width, height, depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_record(record, training=True):\n",
    "    '''Takes as input record which is an array of shape [3072,] and training which is a boolean variable used to determine if the process is in training mode and returns an array of shape [32,32,3]'''\n",
    "    depth_major = record.reshape((3, 32, 32))\n",
    "    image = np.transpose(depth_major, [1, 2, 0])\n",
    "    #image = preprocess_image(image, training)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45000, 3072)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45000, 32, 32, 3)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train=[]\n",
    "for img in x_train:\n",
    "    train.append(parse_record(img))\n",
    "\n",
    "valid=[]\n",
    "for img in x_valid:\n",
    "    train.append(parse_record(img))\n",
    "\n",
    "test=[]\n",
    "for img in x_test:\n",
    "    train.append(parse_record(img))\n",
    "\n",
    "np.array(train).shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We decide to use the AlexNet as landmark.\n",
    "The architecture consists of 5 Convolutional layers, with the 1st, 2nd and 5th having Max-Pooling layers for proper feature extraction. The Max-Pooling layers are overlapped having strides of 2 with filter size 3Ã—3. They are followed by 2 fully-connected layers (each with dropout) and a softmax layer at the end for predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow.python'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [34], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodels\u001b[39;00m \u001b[39mimport\u001b[39;00m Sequential\n\u001b[0;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlayers\u001b[39;00m \u001b[39mimport\u001b[39;00m Conv2D, Activation, MaxPooling2D, BatchNormalization, Flatten, Dense, Dropout\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\keras\\__init__.py:20\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Copyright 2015 The TensorFlow Authors. All Rights Reserved.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[39m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[39m# limitations under the License.\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[39m# ==============================================================================\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[39m\"\"\"Implementation of the Keras API, the high-level API of TensorFlow.\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \n\u001b[0;32m     17\u001b[0m \u001b[39mDetailed documentation and user guides are available at\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[39m[keras.io](https://keras.io).\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m \u001b[39mimport\u001b[39;00m distribute\n\u001b[0;32m     21\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m \u001b[39mimport\u001b[39;00m models\n\u001b[0;32m     22\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39minput_layer\u001b[39;00m \u001b[39mimport\u001b[39;00m Input\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\keras\\distribute\\__init__.py:18\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Copyright 2019 The TensorFlow Authors. All Rights Reserved.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[39m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[39m# limitations under the License.\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[39m# ==============================================================================\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[39m\"\"\"Keras' Distribution Strategy library.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdistribute\u001b[39;00m \u001b[39mimport\u001b[39;00m sidecar_evaluator\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\keras\\distribute\\sidecar_evaluator.py:17\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Copyright 2020 The TensorFlow Authors. All Rights Reserved.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[39m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[39m# limitations under the License.\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[39m# ==============================================================================\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[39m\"\"\"Python module for evaluation loop.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcompat\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mv2\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtf\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[39m# isort: off\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mplatform\u001b[39;00m \u001b[39mimport\u001b[39;00m tf_logging \u001b[39mas\u001b[39;00m logging\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\tensorflow\\__init__.py:37\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39msys\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39m_sys\u001b[39;00m\n\u001b[0;32m     35\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtyping\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39m_typing\u001b[39;00m\n\u001b[1;32m---> 37\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtools\u001b[39;00m \u001b[39mimport\u001b[39;00m module_util \u001b[39mas\u001b[39;00m _module_util\n\u001b[0;32m     38\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutil\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlazy_loader\u001b[39;00m \u001b[39mimport\u001b[39;00m LazyLoader \u001b[39mas\u001b[39;00m _LazyLoader\n\u001b[0;32m     40\u001b[0m \u001b[39m# Make sure code inside the TensorFlow codebase can use tf2.enabled() at import.\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow.python'"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, Activation, MaxPooling2D, BatchNormalization, Flatten, Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "  \n",
    "# 1st Convolutional Layer\n",
    "model.add(Conv2D(filters = 64, input_shape = (32, 32, 3), \n",
    "            kernel_size = (3, 3), strides = (2, 2), \n",
    "            padding = 'valid'))\n",
    "model.add(Activation('relu'))\n",
    "# Max-Pooling \n",
    "model.add(MaxPooling2D(pool_size = (2, 2),\n",
    "            strides = (2, 2), padding = 'valid'))\n",
    "# Batch Normalisation\n",
    "model.add(BatchNormalization())\n",
    "  \n",
    "\n",
    "# 2nd Convolutional Layer\n",
    "model.add(Conv2D(filters = 192, kernel_size = (3, 3), \n",
    "            strides = (1, 1), padding = 'valid'))\n",
    "model.add(Activation('relu'))\n",
    "# Max-Pooling\n",
    "model.add(MaxPooling2D(pool_size = (2, 2), strides = (2, 2), \n",
    "            padding = 'valid'))\n",
    "# Batch Normalisation\n",
    "model.add(BatchNormalization())\n",
    "  \n",
    "\n",
    "# 3rd Convolutional Layer\n",
    "model.add(Conv2D(filters = 384, kernel_size = (3, 3), \n",
    "            strides = (1, 1), padding = 'valid'))\n",
    "model.add(Activation('relu'))\n",
    "# Batch Normalisation\n",
    "model.add(BatchNormalization())\n",
    "  \n",
    "\n",
    "# 4th Convolutional Layer\n",
    "model.add(Conv2D(filters = 256, kernel_size = (3, 3), \n",
    "            strides = (1, 1), padding = 'valid'))\n",
    "model.add(Activation('relu'))\n",
    "# Batch Normalisation\n",
    "model.add(BatchNormalization())\n",
    "  \n",
    "\n",
    "# 5th Convolutional Layer\n",
    "model.add(Conv2D(filters = 256, kernel_size = (3, 3), \n",
    "            strides = (1, 1), padding = 'valid'))\n",
    "model.add(Activation('relu'))\n",
    "# Max-Pooling\n",
    "model.add(MaxPooling2D(pool_size = (2, 2), strides = (2, 2), \n",
    "            padding = 'valid'))\n",
    "# Batch Normalisation\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "\n",
    "# Flattening\n",
    "model.add(Flatten())\n",
    "  \n",
    "# 1st Dense Layer\n",
    "model.add(Dense(4096, input_shape = (224*224*3, )))\n",
    "model.add(Activation('relu'))\n",
    "# Add Dropout to prevent overfitting\n",
    "model.add(Dropout(0.4))\n",
    "# Batch Normalisation\n",
    "model.add(BatchNormalization())\n",
    "  \n",
    "# 2nd Dense Layer\n",
    "model.add(Dense(4096))\n",
    "model.add(Activation('relu'))\n",
    "# Add Dropout\n",
    "model.add(Dropout(0.4))\n",
    "# Batch Normalisation\n",
    "model.add(BatchNormalization())\n",
    "  \n",
    "# Output Softmax Layer\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "\n",
    "## Forse si puÃ² fare direttamente da qua\n",
    "# import torchvision.models as models\n",
    "# squeezenet = models.alexnet(pretrained=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e6bcbf509b47dea4281d29aa6a77a5003802b8ca800c73ace5846e18222006c9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
